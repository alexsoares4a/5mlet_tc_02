name: "Scraping B3 - Execução Diária"

on:
  schedule:
    # Executa diariamente às 8h da manhã (UTC)
    - cron: "0 8 * * *"
  workflow_dispatch: # Para rodar manualmente

jobs:
  run-scraping:
    name: "Executar scraping e enviar para S3"
    runs-on: ubuntu-latest
    permissions:
      contents: read
      # secrets: write  # Se precisar atualizar segredos (não é comum)

    steps:
      - name: "Checkout do repositório"
        uses: actions/checkout@v3

      - name: "Configurar Python"
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: "Instalar dependências"
        run: |
          pip install -r requirements.txt
          playwright install chromium

      - name: "Rodar script de scraping"
        env:
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          AWS_DEFAULT_REGION: us-east-1
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }} 
        run: |
          python scraping_b3.py