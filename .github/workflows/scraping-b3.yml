name: "Scraping B3 - Execução Diária"

on:
  schedule:
    # Executa diariamente às 8h da manhã (UTC)
    - cron: "0 8 * * *"
  workflow_dispatch: # Para rodar manualmente

jobs:
  run-scraping:
    name: "Executar scraping e enviar para S3"
    runs-on: ubuntu-latest
    permissions:
      contents: read
      # secrets: write  # Se precisar atualizar segredos (não é comum)

    steps:
      - name: "Checkout do repositório"
        uses: actions/checkout@v3

      - name: "Configurar Python"
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: "Instalar dependências"
        run: |
          pip install -r requirements.txt
          playwright install chromium

      - name: "Rodar script de scraping"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          python scraping_b3.py